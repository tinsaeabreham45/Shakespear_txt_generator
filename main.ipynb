{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4ea3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0094e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = f'./data/shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77edd5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to die than to famish?\n",
      "\n",
      "all:\n",
      "resolved. resolved.\n",
      "\n",
      "first citizen:\n",
      "first, you know caius marcius is chief enemy to the people.\n",
      "\n",
      "all:\n",
      "we know't, we know't.\n",
      "\n",
      "first citizen:\n",
      "let us\n"
     ]
    }
   ],
   "source": [
    "# read and decode the data\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "# check the text \n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef697fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# create the vocab \n",
    "vocab = sorted(set(text))\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "608251b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding string to numerical value using StringLookUp \n",
    "\n",
    "# create a token first \n",
    "example_texts = ['abcdefg', 'xyz']\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding = 'UTF-8')\n",
    "\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary = list(vocab), \n",
    "    mask_token = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee3e699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[14, 15, 16, 17, 18, 19, 20], [37, 38, 39]]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2598aad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_from_id = tf.keras.layers.StringLookup(\n",
    "    vocabulary = ids_from_chars.get_vocabulary(),\n",
    "    invert = True, \n",
    "    mask_token = None\n",
    ")\n",
    "\n",
    "chars = chars_from_id(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3fa0452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_id(ids), axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f346fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "for id in ids_dataset.take(10):\n",
    "    print(chars_from_id(id).numpy().decode('utf-8')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82077302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'f' b'i' b'r' b's' b't' b' ' b'c' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'b' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'a' b'l' b'l' b':' b'\\n' b's' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'f' b'i'\n",
      " b'r' b's' b't' b' ' b'c' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# see the sequence\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_id(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c9e3f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'first citizen:\\nbefore we proceed any further, hear me speak.\\n\\nall:\\nspeak, speak.\\n\\nfirst citizen:\\nyou '\n"
     ]
    }
   ],
   "source": [
    "# see the actual sentence \n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(text_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13d5ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the input and label from the sequence\n",
    "\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f42ee367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Text :  b'first citizen:\\nbefore we proceed any further, hear me speak.\\n\\nall:\\nspeak, speak.\\n\\nfirst citizen:\\nyou'\n",
      "label Text :  b'irst citizen:\\nbefore we proceed any further, hear me speak.\\n\\nall:\\nspeak, speak.\\n\\nfirst citizen:\\nyou '\n"
     ]
    }
   ],
   "source": [
    "dataset_split = sequences.map(split_input_target)\n",
    "\n",
    "for ex_input, ex_target in dataset_split.take(1):\n",
    "    print(\"input Text : \", text_from_ids(ex_input))\n",
    "    print(\"label Text : \", text_from_ids(ex_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f7e9b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 100), dtype=tf.int64, name=None), TensorSpec(shape=(None, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the batch and shuffle the dataset\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset_split\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12195c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model variable / parameter\n",
    "\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_unit = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6e86fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.GRU(rnn_unit, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7179a063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 40) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0468a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m10,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m40\u001b[0m)          │        \u001b[38;5;34m41,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,989,544</span> (15.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,989,544\u001b[0m (15.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,989,544</span> (15.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,989,544\u001b[0m (15.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b820c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'f the duke is with the soldiers;\\nand for your brother, he was lately sent\\nfrom your kind aunt, duche'\n",
      "\n",
      "Next Char Predictions:\n",
      " b\"q&:y3ua'''jlypm&ecfyls!!kphuf$;vzip;h\\npwu.lgr3;o?z\\n$bhh3rog- wwxir\\n&udq'ga!nr?ge&:!f[UNK]ms..vmtqj;b[UNK]l&t\"\n"
     ]
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices\n",
    "\n",
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4307054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 40)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(3.6867273, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss, metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fe7a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 3s/step - loss: 2.9008 - sparse_categorical_accuracy: 0.2546\n",
      "Epoch 2/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 3s/step - loss: 1.8735 - sparse_categorical_accuracy: 0.4392\n",
      "Epoch 3/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 3s/step - loss: 1.5847 - sparse_categorical_accuracy: 0.5186\n",
      "Epoch 4/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 3s/step - loss: 1.4494 - sparse_categorical_accuracy: 0.5538\n",
      "Epoch 5/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 3s/step - loss: 1.3719 - sparse_categorical_accuracy: 0.5733\n",
      "Epoch 6/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 3s/step - loss: 1.3173 - sparse_categorical_accuracy: 0.5871\n",
      "Epoch 7/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 3s/step - loss: 1.2720 - sparse_categorical_accuracy: 0.5987\n",
      "Epoch 8/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 2s/step - loss: 1.2302 - sparse_categorical_accuracy: 0.6101\n",
      "Epoch 9/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 3s/step - loss: 1.1888 - sparse_categorical_accuracy: 0.6219\n",
      "Epoch 10/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 2s/step - loss: 1.1465 - sparse_categorical_accuracy: 0.6345\n",
      "Epoch 11/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 2s/step - loss: 1.1029 - sparse_categorical_accuracy: 0.6477\n",
      "Epoch 12/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 2s/step - loss: 1.0583 - sparse_categorical_accuracy: 0.6615\n",
      "Epoch 13/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - loss: 1.0135 - sparse_categorical_accuracy: 0.6763\n",
      "Epoch 14/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 4s/step - loss: 0.9761 - sparse_categorical_accuracy: 0.6872\n",
      "Epoch 15/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 3s/step - loss: 0.9550 - sparse_categorical_accuracy: 0.6931\n",
      "Epoch 16/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - loss: 0.9358 - sparse_categorical_accuracy: 0.6979\n",
      "Epoch 17/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 3s/step - loss: 0.9105 - sparse_categorical_accuracy: 0.7063\n",
      "Epoch 18/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 3s/step - loss: 0.8860 - sparse_categorical_accuracy: 0.7135\n",
      "Epoch 19/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 3s/step - loss: 0.8723 - sparse_categorical_accuracy: 0.7167\n",
      "Epoch 20/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 4s/step - loss: 0.8634 - sparse_categorical_accuracy: 0.7186\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6eba6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_id, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_id = chars_from_id\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # create a mask to prevent \"[UNK]\" from being generated\n",
    "\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # put an -inf at each bad index\n",
    "            values = [-float('inf')]*len(skip_ids),\n",
    "            indices = skip_ids,\n",
    "            \n",
    "            # match the size to the vocabulary\n",
    "            dense_shape = [len(ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Embedding layer\n",
    "        x = self.model.layers[0](input_ids)\n",
    "        # GRU layer\n",
    "        x = self.model.layers[1](x, initial_state=states)     \n",
    "        # Get the hidden state of the last timestep\n",
    "        states = x[:, -1, :]\n",
    "        # Dense layer\n",
    "        predicted_logits = self.model.layers[2](x)\n",
    "\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_id(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3bfa2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_id, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ea24387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "nay, madam; 'tis a very looker-bady, i\n",
      "\n",
      "mercutio:\n",
      "do not my cold food?\n",
      "\n",
      "tarisan:\n",
      "on both!\n",
      "\n",
      "coriolanus:\n",
      "you are too soon but book.\n",
      "\n",
      "katharina:\n",
      "what appecialling i stand on, when this isles of person, that\n",
      "i am abused king richer of but which here\n",
      "within me; not i pressing him; you are\n",
      "untimelfachery,\n",
      "and much some slower for that father fret,\n",
      "i warrant them. a\n",
      "thought shall watch the proise hurt upon the world;\n",
      "this bond of others to unactouboth!\n",
      "i promise home:\n",
      "for bitter conferer, is something rich.\n",
      "\n",
      "buckingham:\n",
      "you have been so, but at last word in their\n",
      "cames like unto thee, and master crow,\n",
      "hath brought a like untap' time unto your brother;\n",
      "ere i not proud, which too meet borne thin all-a-rubied is;\n",
      "for my tunes look to help with thee.\n",
      "\n",
      "angelo:\n",
      "\n",
      "duke vincentio:\n",
      "on what tongue not? what, ho! where have won 'em;\n",
      "but thomas told me, boy.\n",
      "\n",
      "polixand\n",
      "of greater:\n",
      "help, yese! why, jood slaining kissing, i never chance\n",
      "proclaimended: ongend at his mind;\n",
      "that thou wouldst disphrietes 'that  \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 6.9804558753967285\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e9cbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.get_custom_objects().update({'OneStep': OneStep})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1f2f7bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "this __dict__ descriptor does not support '_DictWrapper' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_step_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mone_step\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m one_step_reloaded \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_step\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1432\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[1;32m-> 1432\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1434\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1467\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1463\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[0;32m   1464\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[0;32m   1466\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1467\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1468\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1469\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1682\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m \n\u001b[0;32m   1657\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[1;32m-> 1682\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1604\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1601\u001b[0m augmented_graph_view\u001b[38;5;241m.\u001b[39mset_signature(signature_map, wrapped_functions)\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;66;03m# Use _SaveableView to provide a frozen listing of properties and functions.\u001b[39;00m\n\u001b[1;32m-> 1604\u001b[0m saveable_view \u001b[38;5;241m=\u001b[39m \u001b[43m_SaveableView\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_graph_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1605\u001b[0m object_saver \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mTrackableSaver(augmented_graph_view)\n\u001b[0;32m   1606\u001b[0m asset_info, exported_graph \u001b[38;5;241m=\u001b[39m _fill_meta_graph_def(\n\u001b[0;32m   1607\u001b[0m     meta_graph_def\u001b[38;5;241m=\u001b[39mmeta_graph_def,\n\u001b[0;32m   1608\u001b[0m     saveable_view\u001b[38;5;241m=\u001b[39msaveable_view,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1614\u001b[0m     defaults\u001b[38;5;241m=\u001b[39mdefaults,\n\u001b[0;32m   1615\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:285\u001b[0m, in \u001b[0;36m_SaveableView.__init__\u001b[1;34m(self, augmented_graph_view, options)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmented_graph_view \u001b[38;5;241m=\u001b[39m augmented_graph_view\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m options\n\u001b[0;32m    283\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trackable_objects, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_paths, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_ids,\n\u001b[0;32m    284\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slot_variables, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_names) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 285\u001b[0m      \u001b[43mcheckpoint_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects_ids_and_slot_variables_and_paths\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmented_graph_view\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    288\u001b[0m untraced_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmented_graph_view\u001b[38;5;241m.\u001b[39muntraced_functions\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m untraced_functions:\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\util.py:160\u001b[0m, in \u001b[0;36mobjects_ids_and_slot_variables_and_paths\u001b[1;34m(graph_view, skip_slot_variables)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjects_ids_and_slot_variables_and_paths\u001b[39m(graph_view,\n\u001b[0;32m    143\u001b[0m                                              skip_slot_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Traverse the object graph and list all accessible objects.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m  Looks for `Trackable` objects which are dependencies of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m                object -> node id, slot variables, object_names)\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m   trackable_objects, node_paths \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbreadth_first_traversal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m   object_names \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentityDictionary()\n\u001b[0;32m    162\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m obj, path \u001b[38;5;129;01min\u001b[39;00m node_paths\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\graph_view.py:124\u001b[0m, in \u001b[0;36mObjectGraphView.breadth_first_traversal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbreadth_first_traversal\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 124\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_breadth_first_traversal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:156\u001b[0m, in \u001b[0;36m_AugmentedGraphView._breadth_first_traversal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all trackable objects in the SavedObjectGraph.\"\"\"\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# This method is overriden to merge all equivalent constant tensors and\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Assets in the object graph.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m trackable_objects, _ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_breadth_first_traversal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    158\u001b[0m asset_paths \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentityDictionary()\n\u001b[0;32m    159\u001b[0m constant_captures \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentityDictionary()\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\graph_view.py:128\u001b[0m, in \u001b[0;36mObjectGraphView._breadth_first_traversal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_breadth_first_traversal\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    127\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Find shortest paths to all dependencies of self.root.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mObjectGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_descendants_with_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\trackable_view.py:111\u001b[0m, in \u001b[0;36mTrackableView._descendants_with_paths\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m current_trackable \u001b[38;5;241m=\u001b[39m to_visit\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    110\u001b[0m bfs_sorted\u001b[38;5;241m.\u001b[39mappend(current_trackable)\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, dependency \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_trackable\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    112\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dependency \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m node_paths:\n\u001b[0;32m    113\u001b[0m     node_paths[dependency] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    114\u001b[0m         node_paths[current_trackable] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    115\u001b[0m         (base\u001b[38;5;241m.\u001b[39mTrackableReference(name, dependency),))\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\graph_view.py:97\u001b[0m, in \u001b[0;36mObjectGraphView.children\u001b[1;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all child trackables attached to obj.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m  Dictionary of all children attached to the object with name to trackable.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m children \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 97\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m  \u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:190\u001b[0m, in \u001b[0;36m_AugmentedGraphView.list_children\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache:\n\u001b[0;32m    188\u001b[0m   children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache[obj] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 190\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_children\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m      \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSaveType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSAVEDMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialization_cache\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[0;32m    195\u001b[0m       child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_uncache_variable_captures(child)\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\graph_view.py:75\u001b[0m, in \u001b[0;36mObjectGraphView.list_children\u001b[1;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m  List of all children attached to the object.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m children \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mObjectGraphView\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     77\u001b[0m   children\u001b[38;5;241m.\u001b[39mappend(base\u001b[38;5;241m.\u001b[39mTrackableReference(name, ref))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\checkpoint\\trackable_view.py:85\u001b[0m, in \u001b[0;36mTrackableView.children\u001b[1;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m children \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_trackable_children(save_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 85\u001b[0m   ref \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_trackable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m   children[name] \u001b[38;5;241m=\u001b[39m ref\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\trackable\\converter.py:31\u001b[0m, in \u001b[0;36mconvert_to_trackable\u001b[1;34m(obj, parent)\u001b[0m\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m     30\u001b[0m obj \u001b[38;5;241m=\u001b[39m data_structures\u001b[38;5;241m.\u001b[39mwrap_or_unwrap(obj)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_tf_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     obj\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (dtypes\u001b[38;5;241m.\u001b[39mvariant, dtypes\u001b[38;5;241m.\u001b[39mresource) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m resource_variable_ops\u001b[38;5;241m.\u001b[39mis_resource_variable(obj)):\n\u001b[0;32m     34\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_utils\u001b[38;5;241m.\u001b[39mTrackableConstant(obj, parent)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, base\u001b[38;5;241m.\u001b[39mTrackable):\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:1163\u001b[0m, in \u001b[0;36mis_tf_type\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_tf_type\u001b[39m(x):  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether `x` is a TF-native type that can be passed to many TF ops.\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \n\u001b[0;32m   1139\u001b[0m \u001b[38;5;124;03m  Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;124;03m    `True` if `x` is a TensorFlow-native type.\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1163\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_type_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\typing.py:1912\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n\u001b[0;32m   1910\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol_attrs__:\n\u001b[0;32m   1911\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1912\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1913\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   1914\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:1854\u001b[0m, in \u001b[0;36mgetattr_static\u001b[1;34m(obj, attr, default)\u001b[0m\n\u001b[0;32m   1851\u001b[0m     dict_attr \u001b[38;5;241m=\u001b[39m _shadowed_dict(klass)\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types\u001b[38;5;241m.\u001b[39mMemberDescriptorType):\n\u001b[1;32m-> 1854\u001b[0m         instance_result \u001b[38;5;241m=\u001b[39m \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1856\u001b[0m     klass \u001b[38;5;241m=\u001b[39m obj\n",
      "File \u001b[1;32mc:\\Users\\windows 11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:1790\u001b[0m, in \u001b[0;36m_check_instance\u001b[1;34m(obj, attr)\u001b[0m\n\u001b[0;32m   1788\u001b[0m instance_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1790\u001b[0m     instance_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__dict__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: this __dict__ descriptor does not support '_DictWrapper' objects"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
